{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;import pandas as pd;import os,sys;\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from collections import Counter\n",
    "from utils import read_data\n",
    "from sklearn.utils import shuffle;\n",
    "import torch;from torch import nn, Tensor;import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE=128\n",
    "\n",
    "types=\"O\"\n",
    "rna_type=\"pirna\"\n",
    "random_seed=123\n",
    "def seq2kmer(seq):\n",
    "    k=3\n",
    "    kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n",
    "    kmers = \" \".join(kmer)\n",
    "    return kmers\n",
    "\n",
    "all_data=read_data(\"./dataset/set/\"+types+'/'+rna_type+'-short')\n",
    "\n",
    "train_data, val_data = train_test_split(all_data, test_size=0.2, random_state=random_seed)    \n",
    "def get_bert_data():\n",
    "    if os.path.exists(\"./dataset/bert/\"+types+'_'+rna_type):\n",
    "        print(\"目录已存在\")\n",
    "    else:\n",
    "        os.mkdir(\"./dataset/bert/\"+types+'_'+rna_type)\n",
    "    df=train_data.copy(deep=True)\n",
    "    df[\"sequence\"]=df[\"sequence\"].apply(seq2kmer)\n",
    "    df.to_csv(\"./dataset/bert/\"+types+'_'+rna_type+\"/train.tsv\",sep=\"\\t\",index=None)\n",
    "    df=val_data.copy(deep=True)\n",
    "    df[\"sequence\"]=df[\"sequence\"].apply(seq2kmer)\n",
    "    df.to_csv(\"./dataset/bert/\"+types+'_'+rna_type+\"/dev.tsv\",sep=\"\\t\",index=None)\n",
    "get_bert_data()\n",
    "eph=5\n",
    "!python ./DNABERT/examples/run_finetune.py   --early_stop 10 --model_type dna  --tokenizer_name=dna3  --model_name_or_path ./DNABERT/3-new-12w-0  --task_name dnaprom  --do_train  --do_eval  --data_dir ./dataset/bert/{types}_{rna_type} --max_seq_length 101  --per_gpu_eval_batch_size=32    --per_gpu_train_batch_size=32   --learning_rate 3e-5  --num_train_epochs {str(eph)}  --output_dir ./results/models/bert/{types}_{rna_type}  --evaluate_during_training  --logging_steps 100  --save_steps 100  --warmup_percent 0.1  --hidden_dropout_prob 0.1  --overwrite_output  --weight_decay 0.01  --n_process 40  --fp16\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
